<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>CNIT 58100-RDM | Responsible Data Science Lab at Purdue</title> <meta name="author" content="Responsible Data Science Lab at Purdue"> <meta name="description" content="Graduate course on responsible data science"> <meta name="keywords" content="responsible data science, explainability, ML debugging"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/purdue-favicon.ico?fcd78475832b1fe1eccf62e21a8c39ad"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://romilapradhan.github.io/trustedDS/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Responsible Data Science LabÂ </span>at Purdue</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">group</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/romila/">Dr. Romila Pradhan</a> <a class="dropdown-item" href="/group/">Members</a> </div> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">research</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/publications/">publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/teaching/">CNIT 581-RDM</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">CNIT 58100-RDM</h1> <p class="post-description">Graduate course on responsible data science</p> </header> <article> <header> <b><font size="3em">Purdue CNIT581-RDM: Responsible Data Management</font></b> (archived) <br> Spring 2023<br> <br> Computer &amp; Information Technology<br> Purdue University<br> <p> <b>TL;DR:</b> Interested in data management and/or machine learning? <br> Consider taking CNIT 58100-RDM in Spring 2023. <br> <br><b>Questions?</b> <br>Send an email to the instructor <br>at <a href="mailto:">rpradhan@purdue.edu</a> <section> <h2>COURSE OVERVIEW</h2> <p>Responsible data management (RDM) is a fast-growing research area focused on responsible data handling practices in data-driven decision-making systems. Research in this area is centered around the transparency of data, algorithms, and data science (DS) pipelines. </p> <p>This course examines advanced topics relating to algorithmic fairness, transparency, and interpretability of data-driven decision-making systems. We will study current issues related to the transparency and fairness of data-driven decisions, examine sources of unexpected and discriminatory behavior of data-driven decision-making systems and contrast existing methods and design novel techniques to mitigate undesired system decisions. Topics include algorithmic bias, fairness metrics, debugging and mitigating bias/errors, interpretability of algorithms, the data science lifecycle and bias in the DS pipelines.</p> <p><b>When:</b> TR 3:00 - 4:15 PM</p> <p><b>Where:</b> KNOY Hall, Room B031</p> <p><b>Lecture style:</b> The lectures will be a mix of traditional lectures, paper readings/presentations and practical problem solving, discussing responsible data management from different aspects. As a side goal, we will identify potential open problems for further research.</p> <p><b>Prerequisites:</b> Any undergraduate data management course and exposure to machine learning.</p> <div id="instructor"> <h2>INSTRUCTOR</h2> <a href="https://romilapradhan.github.io">Romila Pradhan</a> <br>Email: <a href="mailto:">rpradhan@purdue.edu</a> <div id="evaluation"> <h2>EVALUATION</h2> There will be 2-3 assignments followed by a semester-long project chosen by the student. Each student is also expected to present 2-3 research presentations. The project will be a group project Students will be evaluated as follows: <ul> <li> Project (40%): proposal + initial draft (5%), presentation (15%), report (20%)</li> <li> Paper presentations (25%): 2-3 in-class presentations</li> <li> Assignments (35%)</li> </ul> <div id="project"> <h2>COURSE PROJECT</h2> For the course project, you will work (individually or in teams of 2 or 3) to produce a research paper and present a research talk during the final weeks of the course. The project description will be provided in the second week of classes. There are four submissions for the class project: the initial project proposal, an intermediate draft of the paper, the final paper, and the final talk. The initial project proposal and the intermediate draft will be submitted primarily for feedback from the instructor. <div id="assignments"> <h2>ASSIGNMENTS</h2> Assignments will consist of reviewing papers and summarizing student paper presentations. During each presentation, each student will provide 3 questions and 3 comments. One of the groups will be responsible for submitting a written report containing a brief review of the paper along with summarized responses to student questions. This written report will be shared with everyone in the class. <div id="schedule"> <h2>TENTATIVE SCHEDULE</h2> <ul> <li> Week 1: Introduction and background</li> <li> Week 2: Algorithmic fairness</li> <li> Week 3: Data science lifecycle and bias in data science pipelines</li> <li> Weeks 4-5: Fairness metrics</li> <li> Weeks 6-7: Bias mitigation techniques</li> <li> Weeks 7-9: Explainability and interpretability of ML models</li> <li> Week 10: SPRING BREAK</li> <li> Weeks 11-15: Debugging ML models and pipelines </li> <li> Week 16: Data management challenges in production ML; Project presentations</li> </ul> </div> <div id="schedule"> <h2>LIST OF PAPERS (tentative)</h2> Week 1: Introduction and background <ul> <li>Julia Stoyanovich, Serge Abiteboul, Bill Howe, H. V. Jagadish, and Sebastian Schelter. 2022. <a href="https://dl.acm.org/doi/10.1145/3488717" rel="external nofollow noopener" target="_blank">Responsible Data Management</a>. Communications of the ACM.</li> <li>Julia Angwin, Jeff Larson, Surya Mattu and Lauren Kirchner. 2016. <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing" rel="external nofollow noopener" target="_blank">Machine Bias.</a> Propublica.</li> </ul> Week 2: Algorithmic fairness <ul> <li>Ramya Srinivasan and Ajay Chander. 2021. <a href="https://doi.org/10.1145/3466132.3466134" rel="external nofollow noopener" target="_blank">Biases in AI Systems: A survey for practitioners</a>. ACM Queue.</li> <li>Batya Friedman and Helen Nissenbaum. 1996. <a href="https://doi.org/10.1145/230538.230561" rel="external nofollow noopener" target="_blank">Bias in computer systems</a>. ACM Transactions on Information Systems.</li> </ul> Week 3: Data science lifecycle and bias in data science pipelines <ul> <li>Jeanette. M. Wing. 2019. <a href="https://doi.org/10.1162/99608f92.e26845b4" rel="external nofollow noopener" target="_blank">The Data Life Cycle</a>. Harvard Data Science Review</li> <li>Sumon Biswas, Mohammad Wardat, and Hridesh Rajan. 2022. <a href="https://doi.org/10.1145/3510003.3510057" rel="external nofollow noopener" target="_blank">The art and practice of data science pipelines: A comprehensive study of data science pipelines in theory, in-the-small, and in-the-large</a>. In Proceedings of the 44th International Conference on Software Engineering (ICSE '22)</li> </ul> Weeks 4-5: Fairness metrics <ul> <li>Ninareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, and Aram Galstyan. 2021. <a href="https://doi.org/10.1145/3457607" rel="external nofollow noopener" target="_blank">A Survey on Bias and Fairness in Machine Learning</a>. ACM Computing Surveys.</li> <li>Sahil Verma and Julia Rubin. 2018. <a href="https://fairware.cs.umass.edu/papers/Verma.pdf" rel="external nofollow noopener" target="_blank">Fairness Definitions Explained</a>. 2018 ACM/IEEE International Workshop on Software Fairness.</li> <li>Dana Pessach and Erez Shmueli. 2022. <a href="https://doi.org/10.1145/3494672" rel="external nofollow noopener" target="_blank">A Review on Fairness in Machine Learning</a>. ACM Computing Surveys. (Sections 1 through 3)</li> </ul> Week 6: Bias mitigation techniques (pre-processing) <ul> <li>Faisal Kamiran and Toon Calders. 2012. <a href="https://doi.org/10.1007/s10115-011-0463-8" rel="external nofollow noopener" target="_blank">Data preprocessing techniques for classification without discrimination</a>. Knowledge and Information Systems. (Presenter: Anuj; Summary: Xinning, Mensah)</li> <li>Michael Feldman, Sorelle A. Friedler, John Moeller, Carlos Scheidegger, and Suresh Venkatasubramanian. 2015. <a href="https://doi.org/10.1145/2783258.2783311" rel="external nofollow noopener" target="_blank">Certifying and Removing Disparate Impact</a>. In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD '15). (Presenter: Shashank; Summary: Tejendra, Dairian)</li> <li>Zemel, R., Wu, Y., Swersky, K., Pitassi, T. &amp; Dwork, C.. 2013. <a href="https://proceedings.mlr.press/v28/zemel13.html" rel="external nofollow noopener" target="_blank">Learning Fair Representations</a>. <i>Proceedings of the 30th International Conference on Machine Learning</i>, in <i>Proceedings of Machine Learning Research</i>. (Presenter: Kevin; Summary: Yuzhe, Meher) </li> <li>Babak Salimi, Luke Rodriguez, Bill Howe, and Dan Suciu. 2019. <a href="https://doi.org/10.1145/3299869.3319901" rel="external nofollow noopener" target="_blank">Interventional Fairness: Causal Database Repair for Algorithmic Fairness</a>. In Proceedings of the 2019 International Conference on Management of Data (SIGMOD '19). (Presenter: Yi; Summary: Divya, Ekta)</li> </ul> Week 7: Bias mitigation techniques (in-processing + post-processing) <ul> <li> Muhammad Bilal Zafar, Isabel Valera, Manuel Gomez Rodriguez, and Krishna P. Gummadi. 2017. <a href="https://doi.org/10.1145/3038912.3052660" rel="external nofollow noopener" target="_blank">Fairness Beyond Disparate Treatment &amp; Disparate Impact: Learning Classification without Disparate Mistreatment</a>. In Proceedings of the 26th International Conference on World Wide Web (WWW '17). (Presenter: Ekta; Summary: Yi, Kevin)</li> <li> Maya Gupta, Andrew Cotter, Mahdi Milani Fard, and Serena Wang. 2018. <a href="https://arxiv.org/pdf/1806.11212.pdf" rel="external nofollow noopener" target="_blank">Proxy Fairness</a>. arXiv. (Presenter: Divya; Summary: Shashank, Anuj)</li> <li> Moritz Hardt, Eric Price, and Nathan Srebro. 2016. <a href="https://papers.nips.cc/paper/2016/hash/9d2682367c3935defcb1f9e247a97c0d-Abstract.html" rel="external nofollow noopener" target="_blank">Equality of opportunity in supervised learning</a>. In Proceedings of the 30th International Conference on Neural Information Processing Systems (NIPS'16). (Presenter: Meher; Summary: Xinning, Tejendra)</li> <li> Dwork, C., Immorlica, N., Kalai, A.T. &amp; Leiserson, M.. (2018). <a href="https://proceedings.mlr.press/v81/dwork18a.html" rel="external nofollow noopener" target="_blank">Decoupled Classifiers for Group-Fair and Efficient Machine Learning</a>. <i>Proceedings of the 1st Conference on Fairness, Accountability and Transparency</i>, in <i>Proceedings of Machine Learning Research</i>. (Presenter: Yuzhe; Summary: Mensah, Dairian)</li> </ul> Week 8: Explainability and interpretability of ML models <ul> <li>Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. 2016. <a href="https://doi.org/10.1145/2939672.2939778" rel="external nofollow noopener" target="_blank">Why Should I Trust You?": Explaining the Predictions of Any Classifier</a>. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD '16). (Presenter: Dairian; Summary: Yuzhe, Divya)</li> <li>Scott M. Lundberg and Su-In Lee. 2017. <a href="https://proceedings.neurips.cc/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf" rel="external nofollow noopener" target="_blank">A unified approach to interpreting model predictions</a>. In Proceedings of the 31st International Conference on Neural Information Processing Systems (NIPS'17). (Presenter: Tejendra; Summary: Meher, Ekta)</li> <li>Koh, P.W. &amp; Liang, P.. (2017). <a href="https://proceedings.mlr.press/v70/koh17a.html" rel="external nofollow noopener" target="_blank">Understanding Black-box Predictions via Influence Functions</a>. <i>Proceedings of the 34th International Conference on Machine Learning</i>, in <i>Proceedings of Machine Learning Research</i>. (Presenter: Mensah; Summary: Yi, Kevin)</li> <li>Ghorbani, A. &amp; Zou, J.. (2019). <a href="https://proceedings.mlr.press/v97/ghorbani19c.html" rel="external nofollow noopener" target="_blank">Data Shapley: Equitable Valuation of Data for Machine Learning</a>. <i>Proceedings of the 36th International Conference on Machine Learning</i>, in <i>Proceedings of Machine Learning Research</i>. (Presenter: Xinning; Summary: Shashank, Anuj)</li> </ul> Week 9: Debugging ML models and pipelines (model performance) <ul> <li>Chung, Y., Kraska, T., Polyzotis, N., Tae, K. H., &amp; Whang, S. E. 2019. <a href="https://research.google/pubs/pub47966/" rel="external nofollow noopener" target="_blank">Slice finder: Automated data slicing for model validation</a>. In 2019 IEEE 35th International Conference on Data Engineering (ICDE). (Presenter: Shashank; Summary: Yi, Mensah)</li> <li>Weiyuan Wu, Lampros Flokas, Eugene Wu, and Jiannan Wang. 2020. <a href="https://doi.org/10.1145/3318464.3389696" rel="external nofollow noopener" target="_blank">Complaint-driven Training Data Debugging for Query 2.0</a>. In Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data (SIGMOD '20). (Presenter: Anuj; Summary: Kevin, Ekta)</li> <li>Laure Berti-Equille. 2019. <a href="https://doi.org/10.1145/3308558.3313602" rel="external nofollow noopener" target="_blank">Learn2Clean: Optimizing the Sequence of Tasks for Web Data Preparation</a>. In The World Wide Web Conference (WWW '19). (Presenter: Kevin; Summary: Anuj, Tejendra)</li> <li>Yanhui Li, Linghan Meng, Lin Chen, Li Yu, Di Wu, Yuming Zhou, and Baowen Xu. 2022. <a href="https://doi.org/10.1145/3510003.3510091" rel="external nofollow noopener" target="_blank">Training data debugging for the fairness of machine learning software</a>. In Proceedings of the 44th International Conference on Software Engineering (ICSE '22). (Presenter: Yi; Summary: Divya, Dairian)</li> </ul> Week 10: SPRING BREAK<br><br> Week 11: Debugging ML models and pipelines (model performance) <ul> <li>Junwen Yang, Yeye He, and Surajit Chaudhuri. 2021. <a href="https://doi.org/10.14778/3476249.3476303" rel="external nofollow noopener" target="_blank">Auto-pipeline: synthesizing complex data pipelines by-target using reinforcement learning and search</a>. Proceedings of the VLDB Endowment. (Presenter: Ekta; Summary: Shashank, Yuzhe)</li> <li>Robin Cugny, Julien Aligon, Max Chevalier, Geoffrey Roman Jimenez, and Olivier Teste. 2022. <a href="https://doi.org/10.1145/3511808.3557247" rel="external nofollow noopener" target="_blank">AutoXAI: A Framework to Automatically Select the Most Adapted XAI Solution</a>. In Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management (CIKM '22). (Presenter: Divya; Summary: Meher, Xinning)</li> <li>Raoni LourenÃ§o, Juliana Freire, and Dennis Shasha. 2020. <a href="https://doi.org/10.1145/3318464.3389763" rel="external nofollow noopener" target="_blank">BugDoc: Algorithms to Debug Computational Processes</a>. In Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data (SIGMOD '20).(Presenter: Meher; Summary: Kevin, Xinning) </li> <li>Sainyam Galhotra, Anna Fariha, Raoni LourenÃ§o, Juliana Freire, Alexandra Meliou, and Divesh Srivastava. 2022. <a href="https://doi.org/10.1145/3514221.3517864" rel="external nofollow noopener" target="_blank">DataPrism: Exposing Disconnect between Data and Systems</a>. In Proceedings of the 2022 International Conference on Management of Data (SIGMOD '22). (Presenter: Yuzhe; Summary: Ekta, Meher)</li> </ul> Week 12: Debugging ML models and pipelines (model performance, data acquisition) <ul> <li>Ki Hyun Tae and Steven Euijong Whang. 2021. <a href="https://doi.org/10.1145/3448016.3452792" rel="external nofollow noopener" target="_blank">Slice Tuner: A Selective Data Acquisition Framework for Accurate and Fair Machine Learning Models</a>. In Proceedings of the 2021 International Conference on Management of Data (SIGMOD '21). (Presenter: Dairian; Summary: Yi, Shashank)</li> <li>A. Asudeh, Z. Jin and H. V. Jagadish. 2019. <a href="https://doi.org/10.1109/ICDE.2019.00056." rel="external nofollow noopener" target="_blank">Assessing and Remedying Coverage for a Given Dataset</a>. IEEE 35th International Conference on Data Engineering (ICDE). (Presenter: Tejendra; Summary: Mensah, Yuzhe)</li> <li>Chengliang Chai, Jiabin Liu, Nan Tang, Guoliang Li, and Yuyu Luo. 2022. <a href="https://doi.org/10.14778/3523210.3523223" rel="external nofollow noopener" target="_blank">Selective data acquisition in the wild for model charging</a>. Proceedings of the VLDB Endowment. (Presenter: Mensah; Summary: Anuj, Dairian)</li> <li>Abolfazl Asudeh, Nima Shahbazi, Zhongjun Jin, and H. V. Jagadish. 2021. <a href="https://www.cs.uic.edu/~indexlab/assets/cov21.pdf" rel="external nofollow noopener" target="_blank">Identifying Insufficient Data Coverage for Ordinal Continuous-Valued Attributes</a>. In Proceedings of the 2021 International Conference on Management of Data (SIGMOD '21). (Presenter: Xinning; Summary: Tejendra, Divya)</li> </ul> Week 13: Debugging ML models and pipelines (impact of data preprocessing, data cleaning) <ul> <li>Sainyam Galhotra, Karthikeyan Shanmugam, Prasanna Sattigeri, and Kush R. Varshney. 2022. <a href="https://doi.org/10.1145/3514221.3517909" rel="external nofollow noopener" target="_blank">Causal Feature Selection for Algorithmic Fairness</a>. In Proceedings of the 2022 International Conference on Management of Data (SIGMOD '22).</li> <li>Nianyun Li, Naman Goel, and Elliott Ash. 2022. <a href="https://doi.org/10.1145/3514094.3534147" rel="external nofollow noopener" target="_blank">Data-Centric Factors in Algorithmic Fairness</a>. In Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society (AIES '22).</li> <li>Yiqiao Liao and Parinaz Naghizadeh. 2023. <a href="https://arxiv.org/pdf/2206.00137.pdf" rel="external nofollow noopener" target="_blank">Social Bias Meets Data Bias: The Impacts of Labeling and Measurement Errors on Fairness Criteria</a>. To appear in Proceedings of AAAI 2023.</li> <li>Sanjay Krishnan, Michael J. Franklin, Ken Goldberg, and Eugene Wu. 2017. <a href="https://arxiv.org/pdf/1711.01299.pdf" rel="external nofollow noopener" target="_blank">BoostClean: Automated Error Detection and Repair for Machine Learning</a>. arXiV.</li> </ul> Week 14: Debugging ML models and pipelines (impact of data processing, data cleaning) <ul> <li>Sanjay Krishnan, Jiannan Wang, Eugene Wu, Michael J. Franklin, and Ken Goldberg. 2016. <a href="https://doi.org/10.14778/2994509.2994514" rel="external nofollow noopener" target="_blank">ActiveClean: interactive data cleaning for statistical modeling</a>. Proceedings of the VLDB Endowment.</li> <li>Lukas Budach, Moritz Feuerpfeil, Nina Ihde, Andrea Nathansen, Nele Noack, Hendrik Patzlaff, Felix Naumann, and Hazar Harmouch. <a href="https://arxiv.org/pdf/2207.14529.pdf" rel="external nofollow noopener" target="_blank">The Effects of Data Quality on Machine Learning Performance</a>. arXiV.</li> <li>Felix Neutatz, Binger Chen, Yazan Alkhatib, Jingwen Ye &amp; Ziawasch Abedjan. 2022. <a href="https://doi.org/10.1007/s13222-022-00413-2" rel="external nofollow noopener" target="_blank">Data Cleaning and AutoML: Would an Optimizer Choose to Clean?</a>. Datenbank Spektrum. </li> <li>Yejia Liu, Weiyuan Wu, Lampros Flokas, Jiannan Wang, and Eugene Wu. 2022. <a href="https://dl.acm.org/doi/pdf/10.14778/3494124.3494125" rel="external nofollow noopener" target="_blank">Enabling SQL-based training data debugging for federated learning</a>. Proceedings of the VLDB Endowment</li> </ul> Week 15: Data preparation auto-learning, evaluation <ul> <li>Cong Yan, and Yeye He. <a href="https://congyan.org/JupyterNotebooks.pdf" rel="external nofollow noopener" target="_blank">Auto-Suggest: Learning-to-Recommend Data Preparation Steps Using Data Science Notebooks</a>. SIGMOD 2020</li> <li>Junwen Yang, Yeye He, and Surajit Chaudhuri. 2021. <a href="http://vldb.org/pvldb/vol14/p2563-he.pdf" rel="external nofollow noopener" target="_blank">Auto-pipeline: synthesizing complex data pipelines by-target using reinforcement learning and search</a>. Proceedings of the VLDB Endowment</li> <li>Maliha Tashfia Islam, Anna Fariha, Alexandra Meliou, and Babak Salimi. 2022. <a href="https://doi.org/10.1145/3514221.3517841" rel="external nofollow noopener" target="_blank">Through the Data Management Lens: Experimental Analysis and Evaluation of Fair Classification</a>. In Proceedings of the 2022 International Conference on Management of Data (SIGMOD '22).</li> <li>Sumon Biswas and Hridesh Rajan. 2021. <a href="https://doi.org/10.1145/3468264.3468536" rel="external nofollow noopener" target="_blank">Fair preprocessing: towards understanding compositional fairness of data transformers in machine learning pipeline</a>. In Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE 2021).</li> </ul> Week 16: Project presentations </div> </div> </div> </div> </div></section></p></header> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> Â© Copyright 2025 Responsible Data Science Lab at Purdue. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>